import os
import torch
import torch.nn as nn
import hydra
import numpy as np
import glob
import pytorch_kinematics as pk
import xml.etree.ElementTree as ET
import multiprocessing as mp
import joblib
from isaaclab.utils.math import quat_mul, quat_error_magnitude

from smplx import SMPL
from scipy.spatial.transform import Rotation as sRot, Slerp

os.environ["OMP_NUM_THREADS"] = "1"

DATA_PATH = os.path.join(os.path.dirname(__file__), "../data")

SMPL_BONE_ORDER_NAMES = [
    "Pelvis",
    "L_Hip",
    "R_Hip",
    "Torso",
    "L_Knee",
    "R_Knee",
    "Spine",
    "L_Ankle",
    "R_Ankle",
    "Chest",
    "L_Toe",
    "R_Toe",
    "Neck",
    "L_Thorax",
    "R_Thorax",
    "Head",
    "L_Shoulder",
    "R_Shoulder",
    "L_Elbow",
    "R_Elbow",
    "L_Wrist",
    "R_Wrist",
    "L_Hand",
    "R_Hand",
]

def parse_joint_limits_from_mjcf(root):
    limits = {}
    for j in root.findall(".//joint"):
        jtype = j.get("type", "hinge")
        if jtype not in ("hinge", "slide"):
            continue
        name = j.get("name")
        rng = j.get("range")
        if name is None or rng is None:
            continue
        low, high = map(float, rng.split())
        limits[name] = (low, high)
    return limits


def build_chain(cfg) -> pk.Chain:
    mjcf_path = cfg.asset.assetFileName

    tree = ET.parse(mjcf_path)
    root = tree.getroot()

    # remove the free joint of the base link
    root_name = cfg.get("root_name", "pelvis")
    root_body = root.find(f".//body[@name='{root_name}']")
    root_joint = root.find(".//joint[@type='free']")
    root_body.remove(root_joint)
    root_body.set("pos", "0 0 0")

    for extend_config in cfg.extend_config:
        parent = root.find(f".//body[@name='{extend_config.parent_name}']")
        if parent is None:
            raise ValueError(f"Parent body {extend_config.parent_name} not found in MJCF")
        
        pos = extend_config.pos
        rot = extend_config.rot
        # create and insert a dummy body with a fixed joint
        body = ET.Element("body", name=extend_config.joint_name)
        body.set("pos", f"{pos[0]} {pos[1]} {pos[2]}")
        body.set("quat", f"{rot[0]} {rot[1]} {rot[2]} {rot[3]}")
        inertial = ET.Element("inertial", pos="0 0 0", quat="0 0 0 1", mass="0.1", diaginertia="0.1 0.1 0.1")
        body.append(inertial)
        parent.append(body)

    cwd = os.getcwd()
    os.chdir(os.path.dirname(mjcf_path))
    chain = pk.build_chain_from_mjcf(ET.tostring(root, method="xml"), body=root_name)
    os.chdir(cwd)

    joint_limits = parse_joint_limits_from_mjcf(root)
    return chain, joint_limits


def lerp(x, xp, fp):
    return np.stack([np.interp(x, xp, fp[:, i]) for i in range(fp.shape[1])], axis=1)


def slerp(x, xp, fp):
    s = Slerp(xp, sRot.from_rotvec(fp))
    return s(x).as_rotvec()


def fit_motion(cfg, motion_path: str, fitted_shape: torch.Tensor):
    
    with open(motion_path, "rb") as f:
        motion = dict(np.load(f, allow_pickle=True))
    
    if "mocap_framerate" not in motion and "mocap_frame_rate" not in motion:
        print(f"Skipping motion file (no mocap_framerate or mocap_frame_rate): {motion_path}")
        return None
    
    fps = int(motion["mocap_framerate"].item()) if "mocap_framerate" in motion else int(motion["mocap_frame_rate"].item())
    T = motion["poses"].shape[0]
    motion["poses"] = motion["poses"][:, :66].reshape(T, 22, 3)
    if fps != int(cfg.target_fps):
        end_t =  motion["poses"].shape[0] / fps
        xp = np.arange(T) / fps
        x = np.arange(0, end_t, 1 / int(cfg.target_fps))
        if x[-1] > xp[-1]:
            x = x[:-1]
        motion["poses"] = np.stack([
            slerp(x, xp, motion["poses"][:, i])
            for i in range(22)
        ], axis=1)
        motion["trans"] = lerp(x, xp, motion["trans"])
    
    print(f"Retargeting motion at {motion_path} from {fps} to {cfg.target_fps}")

    chain, joint_limits = build_chain(cfg)
    chain.forward_kinematics(torch.zeros(1, chain.n_joints))

    joint_names = chain.get_joint_parameter_names()
    assert len(joint_names) == len(joint_limits), f"Number of joints in chain ({len(joint_names)}) does not match number of joint limits ({len(joint_limits)})"

    low_list, high_list = [], []
    for joint_name, (joint_limit_key, joint_limit_val) in zip(joint_names, joint_limits.items()):
        assert joint_name == joint_limit_key, f"Joint name {joint_name} does not match joint name in joint limits ({joint_limit_key})"
        low_list.append(joint_limit_val[0])
        high_list.append(joint_limit_val[1])
    low = torch.as_tensor(low_list, dtype=torch.float32).unsqueeze(0)   # [1, J]
    high = torch.as_tensor(high_list, dtype=torch.float32).unsqueeze(0) # [1, J]

    T = motion["poses"].shape[0]
    body_pose = torch.as_tensor(motion["poses"][:, 1:], dtype=torch.float32)
    hand_pose = torch.zeros(T, 2, 3)
    data = {
        "body_pose": torch.cat([body_pose, hand_pose], dim=1),
        "global_orient": torch.as_tensor(motion["poses"][:, 0], dtype=torch.float32),
        "trans": torch.as_tensor(motion["trans"], dtype=torch.float32),
    }
    body_model = SMPL(model_path=os.path.join(DATA_PATH, "smpl"), gender="neutral")

    with torch.no_grad():
        result = body_model.forward(
            fitted_shape,
            body_pose=data["body_pose"].reshape(T, 69),
            global_orient=data["global_orient"],
            transl=data["trans"],
            return_full_pose=True
        )
       
    full_pose_aa = result.full_pose  # [T, 72]
    T = full_pose_aa.shape[0]
    
    full_pose_aa = full_pose_aa.reshape(T, 24, 3)
    full_pose_aa_np = full_pose_aa.numpy()  # [T, 24, 3]
    
    # convert axis-angle to quaternions
    smpl_local_quats = np.zeros((T, 24, 4), dtype=np.float32)
    for t in range(T):
        frame_pose = full_pose_aa_np[t]  # [24, 3]
        rotations = sRot.from_rotvec(frame_pose)  
        smpl_local_quats[t] = rotations.as_quat(scalar_first=True)  # [24, 4]
    
    smpl_local_quats = torch.as_tensor(smpl_local_quats, dtype=torch.float32)
    
    parents = body_model.parents

    # compute global quaternions
    smpl_global_quats = torch.zeros(T, 24, 4, dtype=torch.float32)
    smpl_global_quats[:, 0] = smpl_local_quats[:, 0]
    for i in range(1, 24):
        parent_idx = parents[i]
        smpl_global_quats[:, i] = quat_mul(
            smpl_global_quats[:, parent_idx],
            smpl_local_quats[:, i]
        )
    # apply orientation offsets
    smpl_global_quats_modified = smpl_global_quats.clone()
    for joint_name, quat in cfg.quat_offset.items():
        joint_idx = SMPL_BONE_ORDER_NAMES.index(joint_name)
        
        # transform string to list
        if isinstance(quat, str):
            quat_str = quat.strip('[]')
            quat = [float(x.strip()) for x in quat_str.split(',')]
        
        quat_offset = torch.as_tensor(quat, dtype=torch.float32)  # [4]
        for t in range(T):
            smpl_global_quats_modified[t, joint_idx] = quat_mul(
                smpl_global_quats[t, joint_idx:joint_idx+1],
                quat_offset.unsqueeze(0)
            ).squeeze(0)

    # which joints to match
    robot_body_names = []
    smpl_joint_idx = []
    for robot_body_name, smpl_joint_name in cfg.joint_matches:
        robot_body_names.append(robot_body_name)
        smpl_joint_idx.append(SMPL_BONE_ORDER_NAMES.index(smpl_joint_name))
    
    smpl_target_mats = smpl_global_quats_modified[:, smpl_joint_idx]
   
    #print(f"joint_idx={smpl_joint_idx}   robot_body_names={robot_body_names}")   

    # since the betas are changed and so are the SMPL body morphology,
    # we need to make some corrections to avoid ground pentration
    ground_offset = result.vertices[:, :, 2].min()
    smpl_keypoints_w = result.joints[:, smpl_joint_idx] - ground_offset

    # again, convert between Y-up and Z-up
    robot_rot = sRot.from_rotvec(data["global_orient"]) * sRot.from_euler("xyz", [np.pi/2, 0., np.pi/2]).inv()
    root_quat_init = torch.as_tensor(robot_rot.as_quat(scalar_first=True), dtype=torch.float32)
    
    robot_rotmat = torch.as_tensor(robot_rot.as_matrix(), dtype=torch.float32)

    robot_root_quat = torch.nn.Parameter(root_quat_init.clone())

    robot_th = torch.nn.Parameter(torch.zeros(T, chain.n_joints))        
    robot_trans = torch.nn.Parameter(data["trans"].clone() - ground_offset)
    opt = torch.optim.Adam([robot_th, robot_trans, robot_root_quat], lr=0.02)

    indices = chain.get_all_frame_indices()
    
    def mat_rotate(rotmat, v):
        return (rotmat @ v.unsqueeze(-1)).squeeze(-1)

    for i in range(500):
        root_quat_norm = robot_root_quat / (torch.norm(robot_root_quat, dim=-1, keepdim=True) + 1e-9)
        robot_rotmat_opt = pk.quaternion_to_matrix(root_quat_norm)  # [T, 3, 3]
        
    
        fk_output = chain.forward_kinematics(robot_th, indices) # in robot's root frame
        robot_keypoints_b = torch.stack([
            fk_output[name].get_matrix()[:, :3, 3]
            for name in robot_body_names
        ], dim=1)        
        
        robot_keypoints_w = robot_trans.unsqueeze(1) + mat_rotate(robot_rotmat_opt.unsqueeze(1), robot_keypoints_b)
        
        robot_orient_mats_b = torch.stack([
            fk_output[name].get_matrix()[:, :3, :3]
            for name in robot_body_names
        ], dim=1) 
        
        robot_orient_mats_w = torch.matmul(robot_rotmat_opt.unsqueeze(1), robot_orient_mats_b)

        robot_quats_w = pk.matrix_to_quaternion(robot_orient_mats_w)
        robot_quats_w = robot_quats_w / (torch.norm(robot_quats_w, dim=-1, keepdim=True) + 1e-9)
                
        quat_error = quat_error_magnitude(robot_quats_w, smpl_global_quats_modified[:, smpl_joint_idx])  # [T, N]
                
        omega = torch.gradient(robot_th, spacing=1/cfg.target_fps, dim=0)[0]    # [T, J]
        
        violate_low  = torch.relu(low  - robot_th)
        violate_high = torch.relu(robot_th - high)
        L_limit = (violate_low**2 + violate_high**2).mean()

        keypoints_pos_error = nn.functional.mse_loss(robot_keypoints_w, smpl_keypoints_w)
        joint_pos_reg = 1e-2 * torch.mean(torch.square(robot_th))
        joint_vel_reg = 1e-3 * torch.mean(torch.square(omega))
        orientation_error = 1e-2 * torch.mean(torch.square(quat_error))  
        joint_limit_reg = 1e2 * L_limit

        if i < 20:
            # first stage (0-19): only position loss, without this stage the optimization often Collapse
            orientation_error = torch.tensor(0.0)
            loss = keypoints_pos_error + joint_pos_reg + joint_vel_reg + joint_limit_reg            
        
        elif i < 500:
            # second stage (200-399): add orientation loss with small weight
            orientation_error = 1e-2* torch.mean(torch.square(quat_error))
            loss = (keypoints_pos_error + joint_pos_reg + joint_vel_reg + 
                    joint_limit_reg + orientation_error)
        if i == 490:
            print(f"iter {i}, loss {100 * loss.item():.3f}, keypoint_error {100 * keypoints_pos_error.item():.3f}, orientation_error {100 * orientation_error.item():.3f}")
            
        loss = (keypoints_pos_error + joint_pos_reg + joint_vel_reg + 
                joint_limit_reg + orientation_error)
        
        opt.zero_grad()
        loss.backward()        
        opt.step()

    with torch.no_grad():
        robot_rotmat_final = pk.quaternion_to_matrix(robot_root_quat)

        fk_output = chain.forward_kinematics(robot_th, indices)

        robot_keypoints_b = torch.stack([
            fk_output[name].get_matrix()[:, :3, 3]
            for name in chain.get_link_names()
        ], dim=1)        
        
        robot_keypoints_w = robot_trans.unsqueeze(1) + mat_rotate(robot_rotmat_final.unsqueeze(1), robot_keypoints_b)
        
        final_robot_rot = sRot.from_quat(robot_root_quat.detach().numpy(), scalar_first=True)

    split_len = len(cfg.motion_path.split("/"))
    motion_name = "0-" + "_".join(motion_path.split("/")[split_len:]).replace(".npz", "")
    data = {
        "fps": int(cfg.target_fps),
        "joint_pos": robot_th.data.numpy(),
        "root_pos_w": robot_trans.data.numpy(),
        "root_quat_w": final_robot_rot.as_quat(),  
        "body_pos_w": robot_keypoints_w.data.numpy(),
        "body_pos_b": robot_keypoints_b.data.numpy(),
    }
    return motion_name, data


def _worker(args):
    cfg, path, betas = args
    return fit_motion(cfg, path, betas)

@hydra.main(version_base=None, config_path="../cfg", config_name="unitree_g1_fitting")
def main(cfg):
    if os.path.isdir(cfg.motion_path):
        motion_paths = glob.glob(os.path.join(cfg.motion_path, "**/*.npz"), recursive=True)
    else:
        motion_paths = [cfg.motion_path]

    motion_paths = [path for path in motion_paths]
    print(f"Found {len(motion_paths)} motion files under {cfg.motion_path}")

    path = os.path.join(os.path.dirname(__file__), f"{cfg.humanoid_type}_shape.npz")
    fitted_shape = torch.from_numpy(np.load(path)["betas"])


    from tqdm import tqdm
    all_data = {}
    with mp.get_context("spawn").Pool(
        processes=6,
        maxtasksperchild=1,
    ) as pool, tqdm(total=len(motion_paths)) as pbar:
        for result in pool.imap_unordered(
            _worker,
            [(cfg, p, fitted_shape) for p in motion_paths],
            chunksize=1,
        ):
            if result is not None:
                motion_name, data = result
                all_data[motion_name] = data
            pbar.update(1)

    os.makedirs(f"data/{cfg.humanoid_type}", exist_ok=True)
    joblib.dump(all_data, f"data/{cfg.humanoid_type}/{cfg.output_name}.pkl")

if __name__ == "__main__":
    main()  